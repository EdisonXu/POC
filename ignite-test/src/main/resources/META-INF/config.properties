# ===========================
# RMDB c3p0 pool config
# ===========================
c3p0.driverClass = com.mysql.jdbc.Driver
c3p0.jdbcUrl = jdbc:mysql://10.1.110.21:3306/test?useUnicode=true&amp;characterEncoding=utf8
c3p0.user = root
c3p0.password = 111111

#连接池中保留的最大连接数
c3p0.maxPoolSize = 100
#连接池中保留的最小连接数
c3p0.minPoolSize = 10
#当连接池中的连接耗尽的时候c3p0一次同时获取的连接数
c3p0.acquireIncrement = 10
#从数据库获取新连接失败后重复尝试的次数
c3p0.acquireRetryAttempts = 30
#两次连接中间隔时间，单位毫秒
c3p0.acquireRetryDelay = 1000
#连接关闭时默认将所有未提交的操作回滚
c3p0.autoCommitOnClose= true
#每60秒检查所有连接池中的空闲连接
c3p0.idleConnectionTestPeriod = 30
#初始化时获取5个连接
c3p0.initialPoolSize = 5
#最大空闲时间,60秒内未使用则连接被丢弃
c3p0.maxIdleTime = 300
#线程数
c3p0.numHelperThreads = 3
#获取连接超时时间
c3p0.checkoutTimeout = 5000
#获取连接超时时间
c3p0.testConnectionOnCheckout = true

# ===========================
# MongoDB config
# ===========================
mongo.dbName = pbq
#可以是主db，如果是集群，用","分开
mongo.hosts = 10.1.110.24
#连接池大小，应与从该连接池获取连接的bolt并发数相等
mongo.poolSize = 100

# ===========================
# PBQPersistTopology config 
# ===========================
# Kafka存放Broker信息的Zookeeper的URL和端口信息，集群任选一个就行
pbq.persist.zkhosts = 10.1.110.24:2181
pbq.persist.topic = pbq
pbq.persist.partitionNum = 3
# Zookeeper 上kafkaspout用来存储offset的根路径
pbq.persist.mongo.zkRoot = /kafkamongo
pbq.persist.rmdb.zkRoot = /kafkarmdb
pbq.persist.mongo.spoutId = pbqm
pbq.persist.rmdb.spoutId = pbqr

# ===========================
# PBQTransactionalPerisitTopology config 
# ===========================
# Kafka存放Broker信息的Zookeeper的URL和端口信息，集群任选一个就行
pbq.trans.zkhosts = 10.1.110.24:2181
pbq.trans.topic = trans_pbq
pbq.trans.mongo.spoutId = tpbqm
pbq.trans.rmdb.spoutId = tpbqr

# ===========================
# GatheringTopology config 
# ===========================
# Kafka存放Broker信息的Zookeeper的URL和端口信息，集群任选一个就行
gathering.zkhosts = 10.1.110.24:2181
gathering.topic = gather
gathering.partitionNum = 3
# Zookeeper 上kafkaspout用来存储offset的根路径
gathering.zkRoot = /kafkastorm
gathering.spoutId = gastorm
